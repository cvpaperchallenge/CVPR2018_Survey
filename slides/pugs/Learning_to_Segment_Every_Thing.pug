+slide
section#ID_Learning_to_Segment_Every_Thing
  .paper-abstract
    .title Learning to Segment Every Thing
    .info
      .authors Ronghang Hu, Piotr Dollár, Kaiming He, Trevor Darrell, Ross Girshick
      .conference CVPR 2018
    .slide_editor: a(href="http://hirokatsukataoka.net/" target="blank") Hirokatsu Kataoka
  
    .item1
      .text
        h1 概要
        p ラベルが完全に手に入らない際にでも転移学習が可能なセグメンテーション手法（論文中ではPartially Supervised Training Paradigm, weight transfer functionを紹介）を提案する。条件として、bboxが手に入っている物体に対してセグメンテーション領域を学習可能。Mask R-CNNをベースとしているが、Weight Transfer Functionを追加、セグメントの重みを学習・推定して誤差計算と学習繰り返し。
    .item2
      .text
        p
          img(src=`${figpath}180303SegmentEverything.png`,alt="180303SegmentEverything")
    .item3
      .text
        h1 新規性・結果
        p Visual Genome Datasetから3,000の視覚的概念を獲得、MSCOCOから80のマスクアノテーションを獲得した。
    .item4
      .text
        h1 コメント・リンク集
        p 弱教師付き学習が現実的な精度で動作するようになってきた？アノテーションはお金や知識があっても非常に大変なタスクであり、いかに減らすかという方向に研究が進められている。（What's next?ー弱教師/教師なしの先とは？）
        ul
          li
            a(href="https://arxiv.org/pdf/1711.10370.pdf") 論文
          li
            a(href="http://ronghanghu.com/") 著者
          li
            a(href="http://kaiminghe.com/") Kaiming He
    .slide_index #{getSlideIndex()}
    .timestamp 2018.3.3 10:46:40


