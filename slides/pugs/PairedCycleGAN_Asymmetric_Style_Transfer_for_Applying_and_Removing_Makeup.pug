+slide
section#ID_PairedCycleGAN_Asymmetric_Style_Transfer_for_Applying_and_Removing_Makeup
  .paper-abstract
    .title PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup
    .info
      .authors Huiwen Chang et al.
      .conference CVPR 2018
    .slide_editor: a(href="https://sites.google.com/site/shinatoyamamoto/" target="blank") ShintaroYamamoto

    .item1
      .text
        h1 概要
        p ソース画像のメイクをターゲット画像へ転写やメイクの除去をする研究。
          |ターゲット画像とメイク済み画像の2枚を入力としメイクを転写するネットワークGとメイク済み画像らメイクを取り除くネットワークFを考え、2つのネットワークによって元の画像に戻るように学習していく。
          |その際、Fによってxに付与されたメイクがyのメイクと同じものであるかを評価するロスを加えることでメイクの特徴を捉える。
          |従来手法ではメイク転写・除去を独立した問題として考えていたが、この研究ではセットとして考えている。
    .item2
      .text
        p
          img(src=`${figpath}180408make.png`,alt="Item3Image")
    .item3
      .text
        h1 新規性・結果
        p Youtubeのメイクチュートリアルの動画から、1148枚のメイクなし画像と1044枚のメイクあり画像を収集。
          |ユーザースタディによって2つの既存手法と比較し、提案手法が一番いいと答えた人が65.7％（2番目と答えた人が31.4％）
          |従来手法では肌の色や表情の違いがあると上手くいかないのに対し、ソースとターゲット間でこれらが違ってもうまく転写できる。
    .item4
      .text
        h1 リンク集
        ul
          li
            a(href="https://research.adobe.com/project/makeupgan-makeup-transfer-via-cycle-consistent-adversarial-networks/") プロジェクトページ
    .slide_index #{getSlideIndex()}
    .timestamp 2018.4.8 01:45:44
